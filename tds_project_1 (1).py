# -*- coding: utf-8 -*-
"""TDS-Project 1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s6RUBejUEwHaaJlWMibf8xgUSrRuX9Sn
"""

!git clone https://github.com/isha123navare/ISshaTDS1Proj.git

"""Install necessary Python libraries"""

pip install requests pandas

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

"""Scrape Data Using the GitHub API.

Authenticate with the GitHub API using the PAT. Here's how you can use the requests library:
"""

import requests

GITHUB_TOKEN = ''  # Replace with your actual token
headers = {'Authorization': f'token {GITHUB_TOKEN}'}

url = 'https://api.github.com/search/users?q=location:Berlin+followers:>200'
response = requests.get(url, headers=headers)
users = response.json().get('items', [])

users_data = []
for user in users:
    user_url = f"https://api.github.com/users/{user['login']}"
    user_data = requests.get(user_url, headers=headers).json()
    users_data.append(user_data)

def clean_company(company):
    if company:
        company = company.strip().lstrip('@').upper()
    return company or ''

cleaned_data = [
    {
        "login": user['login'],
        "name": user.get('name', ''),
        "company": clean_company(user.get('company')),
        "location": user.get('location', ''),
        "email": user.get('email', ''),
        "hireable": str(user.get('hireable', '')).lower(),
        "bio": user.get('bio', ''),
        "public_repos": user['public_repos'],
        "followers": user['followers'],
        "following": user['following'],
        "created_at": user['created_at']
    }
    for user in users_data
]

repos_data = []
for user in users:
    repo_url = f"https://api.github.com/users/{user['login']}/repos?per_page=500"
    repos = requests.get(repo_url, headers=headers).json()
    for repo in repos:
        repos_data.append({
            "login": user['login'],
            "full_name": repo['full_name'],
            "created_at": repo['created_at'],
            "stargazers_count": repo['stargazers_count'],
            "watchers_count": repo['watchers_count'],
            "language": repo.get('language', ''),
            "has_projects": str(repo.get('has_projects', '')).lower(),
            "has_wiki": str(repo.get('has_wiki', '')).lower(),
            "license_name": repo.get('license', {}).get('key', '') if repo.get('license') else ''
        })

import pandas as pd

users_df = pd.DataFrame(cleaned_data)
users_df.to_csv('users.csv', index=False)

repos_df = pd.DataFrame(repos_data)
repos_df.to_csv('repositories.csv', index=False)

import requests
import csv

GITHUB_TOKEN = "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"
HEADERS = {"Authorization": f"token {GITHUB_TOKEN}"}

def get_users_in_berlin():
    users = []
    query = "location:Berlin+followers:>10"
    page = 1
    per_page = 100
    total_users = 0

    while True:
        url = f"https://api.github.com/search/users?q={query}&per_page={per_page}&page={page}"
        response = requests.get(url, headers=HEADERS)
        print(f"Fetching page {page}...")

        if response.status_code != 200:
            print("Error fetching data:", response.json())
            break

        data = response.json()
        users.extend(data['items'])
        total_users += len(data['items'])

        if len(data['items']) < per_page:
            break

        page += 1

    detailed_users = []
    for user in users:
        user_info = get_user_details(user['login'])
        detailed_users.append(user_info)

    return detailed_users

def get_user_details(username):
    user_url = f"https://api.github.com/users/{username}"
    user_data = requests.get(user_url, headers=HEADERS).json()

    return {
        'login': user_data['login'],
        'name': user_data['name'],
        'company': clean_company_name(user_data['company']),
        'location': user_data['location'],
        'email': user_data['email'],
        'hireable': user_data['hireable'],
        'bio': user_data['bio'],
        'public_repos': user_data['public_repos'],
        'followers': user_data['followers'],
        'following': user_data['following'],
        'created_at': user_data['created_at'],
    }

def clean_company_name(company):
    if company:
        company = company.strip().upper()
        if company.startswith('@'):
            company = company[1:]
    return company

def get_user_repos(username):
    repos_url = f"https://api.github.com/users/{username}/repos?per_page=500"
    response = requests.get(repos_url, headers=HEADERS)
    repos_data = response.json()

    repos = []
    for repo in repos_data:
        repos.append({
            'login': username,
            'full_name': repo['full_name'],
            'created_at': repo['created_at'],
            'stargazers_count': repo['stargazers_count'],
            'watchers_count': repo['watchers_count'],
            'language': repo['language'],
            'has_projects': repo['has_projects'],
            'has_wiki': repo['has_wiki'],
            'license_name': repo['license']['key'] if repo['license'] else None,
        })

    return repos

def save_users_to_csv(users):
    with open('users.csv', mode='w', newline='') as file:
        writer = csv.DictWriter(file, fieldnames=['login', 'name', 'company', 'location', 'email', 'hireable', 'bio', 'public_repos', 'followers', 'following', 'created_at'])
        writer.writeheader()
        writer.writerows(users)

def save_repos_to_csv(repos):
    with open('repositories.csv', mode='w', newline='') as file:
        writer = csv.DictWriter(file, fieldnames=['login', 'full_name', 'created_at', 'stargazers_count', 'watchers_count', 'language', 'has_projects', 'has_wiki', 'license_name'])
        writer.writeheader()
        writer.writerows(repos)

if __name__ == "__main__":
    users = get_users_in_berlin()
    save_users_to_csv(users)

    all_repos = []
    for user in users:
        repos = get_user_repos(user['login'])
        all_repos.extend(repos)

    save_repos_to_csv(all_repos)
    print("Done")

"""QUESTION 1: Who are the top 5 users in Berlin with the highest number of followers? List their login in order, comma-separated.
italicized text
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

users = pd.read_csv('users.csv')
users.head()

users['hireable'] = users['hireable'].fillna(False).astype(bool)

top5 = users.sort_values(by='followers', ascending=False).head()
print(','.join(top5['login'].tolist()))

"""QUESTION 2: Who are the 5 earliest registered GitHub users in Berlin? List their login in ascending order of created_at, comma-separated."""

users['created_at'] = pd.to_datetime(users['created_at'])

top_earliest = users.sort_values(by='created_at').head()
print(','.join(top_earliest['login'].tolist()))

"""QUESTION 3: What are the 3 most popular license among these users? Ignore missing licenses. List the license_name in order, comma-separated."""

repos = pd.read_csv('repositories.csv')
repos.head()

repos['license_name'].value_counts().head(3)

"""QUESTION 4: Which company do the majority of these developers work at?

"""

users['company'].value_counts().head(1)

"""QUESTION 5: Which programming language is most popular among these users?"""

repos['language'].value_counts().head(1)

"""QUESTION 6: Which programming language is the second most popular among users who joined after 2020?"""

users_after_2020 = users[users['created_at'] > '2020-01-01']
users_after_2020.head()

repos_2020 = repos[repos['login'].isin(users_after_2020['login'].tolist())]
repos_2020['language'].value_counts().head()

"""QUESTION 7: Which language has the highest average number of stars per repository?"""

avg_stars = repos.groupby('language')['stargazers_count'].mean()
top_lang = avg_stars.idxmax()
top_stars = avg_stars.max()
print(top_lang, top_stars)

"""QUESTION 8: Let's define leader_strength as followers / (1 + following). Who are the top 5 in terms of leader_strength? List their login in order, comma-separated."""

users['leader_strength'] = users['followers'] / (1 + users['following'])
top5_lead = users.sort_values(by='leader_strength', ascending=False).head()
print(','.join(top5_lead['login'].tolist()))

"""QUESTION 9: What is the correlation between the number of followers and the number of public repositories among users in Berlin?"""

correlation = users['followers'].corr(users['public_repos'])
correlation

"""QUESTION 10: Does creating more repos help users get more followers? Using regression, estimate how many additional followers a user gets per additional public repository."""

import csv
followers = []
public_repos = []
with open('users.csv', 'r', encoding='utf-8') as file:
    reader = csv.DictReader(file)
    for row in reader:
        followers_count = int(row['followers'])
        public_repos_count = int(row['public_repos'])
        followers.append(followers_count)
        public_repos.append(public_repos_count)
if len(followers) > 1 and len(public_repos) > 1:
    slope, intercept = np.polyfit(public_repos, followers, 1)

    print(f"{slope:.3f}")
else:
    print("Error")

"""QUESTION 11: Do people typically enable projects and wikis together? What is the correlation between a repo having projects enabled and having wiki enabled?"""

if repos['has_projects'].dtype == 'object':
    repos['has_projects'] = repos['has_projects'].map({'true': True, 'false': False})
if repos['has_wiki'].dtype == 'object':
    repos['has_wiki'] = repos['has_wiki'].map({'true': True, 'false': False})

correlation = repos['has_projects'].corr(repos['has_wiki'])

print(round(correlation, 3))

"""QUESTION 12: Do hireable users follow more people than those who are not hireable?"""

print(users[users['hireable'] == True])
print(users[users['hireable'] == False])

print(users['following'].isna().sum())

hireable_avg_following = users[users['hireable'] == True]['following'].mean()
non_hireable_avg_following = users[users['hireable'] == False]['following'].mean()
difference = hireable_avg_following - non_hireable_avg_following
print(difference)

"""QUESTION 13: Some developers write long bios. Does that help them get more followers? What's the correlation of the length of their bio (in Unicode characters) with followers? (Ignore people without bios)"""

from sklearn.linear_model import LinearRegression
users_with_bio = users[(users['bio'].notna()) & (users['bio'] != '')].copy()
users_with_bio.loc[:, 'bio_len'] = users_with_bio['bio'].str.len()

X = users_with_bio['bio_len'].values.reshape(-1,1)
y = users_with_bio['followers']

lr2 = LinearRegression()
lr2.fit(X, y)
lr2.coef_[0]

"""QUESTION 14: Who created the most repositories on weekends (UTC)? List the top 5 users' login in order, comma-separated"""

import csv
from collections import Counter
from datetime import datetime

weekend_repo_counts = Counter()

with open('repositories.csv', 'r', encoding='utf-8') as file:
    reader = csv.DictReader(file)

    for row in reader:
        created_at = row.get('created_at', '')
        if created_at:
            created_date = datetime.fromisoformat(created_at[:-1])

            if created_date.weekday() in [5, 6]:
                user_login = row['login']
                weekend_repo_counts[user_login] += 1

top_users = weekend_repo_counts.most_common(5)

top_logins = [user[0] for user in top_users]

print(','.join(top_logins))

"""QUESTION 15: Do people who are hireable share their email addresses more often?"""

fraction_hierable = users[users['hireable'] == True]['email'].notna().mean()
fraction_non_hierable = users[users['hireable'] == False]['email'].notna().mean()
diff = fraction_hierable - fraction_non_hierable
diff

"""QUESTION 16: Let's assume that the last word in a user's name is their surname (ignore missing names, trim and split by whitespace.) What's the most common surname? (If there's a tie, list them all, comma-separated, alphabetically)"""

new_users = users[users['name'].notna()].copy()
new_users['surname'] = new_users['name'].str.split().str[-1].str.strip()
surname_counts = new_users['surname'].value_counts()
max_count = surname_counts.max()
common_surnames = surname_counts[surname_counts == max_count].index.tolist()
common_surnames.sort()
print(','.join(common_surnames))